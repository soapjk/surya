{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT']='https://hf-mirror.com'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True'\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO']='0.0'\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from surya.input.langs import replace_lang_with_code\n",
    "from surya.input.load import load_from_folder, load_from_file, load_lang_file\n",
    "from surya.model.detection.model import load_model as load_detection_model, load_processor as load_detection_processor\n",
    "from surya.model.recognition.model import load_model as load_recognition_model\n",
    "from surya.model.recognition.processor import load_processor as load_recognition_processor\n",
    "from surya.ocr import run_ocr\n",
    "from surya.postprocessing.text import draw_text_on_image\n",
    "from surya.settings import settings\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class box_text:\n",
    "    left_top_x=0\n",
    "    left_top_y=0\n",
    "    right_bottom_x=0\n",
    "    right_bottom_y =0\n",
    "    text=\"\"\n",
    "    x=0\n",
    "    y=0\n",
    "    def __init__(self,left_top_x,left_top_y,right_bottom_x,right_bottom_y,text):\n",
    "        self.left_top_x=left_top_x\n",
    "        self.left_top_y=left_top_y\n",
    "        self.right_bottom_x=right_bottom_x\n",
    "        self.right_bottom_y =right_bottom_y\n",
    "        self.text=text\n",
    "    def set_coordinate(self,x,y):\n",
    "        self.x = x\n",
    "        self.y=y\n",
    "def generate_csv(bboxes,texts,file_path):\n",
    "    length = len(bboxes)\n",
    "    last_top = None\n",
    "    last_bottom = None\n",
    "    lines = []\n",
    "    line = []\n",
    "    box_text_arr = []\n",
    "    for idx in range(length):\n",
    "        bbox = bboxes[idx]\n",
    "        left_top_x = bbox[0]\n",
    "        left_top_y = bbox[1]\n",
    "        right_bottom_x = bbox[2] \n",
    "        right_bottom_y = bbox[3]\n",
    "        text = texts[idx]\n",
    "        box = box_text(left_top_x,left_top_y,right_bottom_x,right_bottom_y,text)\n",
    "        box_text_arr.append(box)\n",
    "    box_text_arr.sort(key=lambda x:x.left_top_y)\n",
    "    for idx in range(length):\n",
    "        bbox = box_text_arr[idx]\n",
    "        left_top_y = bbox.left_top_y\n",
    "        right_bottom_y = bbox.right_bottom_y\n",
    "        same_line = False\n",
    "        if last_bottom is None or ((last_bottom >= left_top_y>=last_top)):\n",
    "            same_line = True\n",
    "        if not same_line:\n",
    "            line.sort(key=lambda x:x.left_top_x)\n",
    "            lines.append(line)\n",
    "            line = [bbox]\n",
    "        else:\n",
    "            line.append(bbox)\n",
    "        last_bottom = right_bottom_y\n",
    "        last_top = left_top_y\n",
    "    lines.append(line)\n",
    "    for y in range(len(lines)):\n",
    "        line = lines[y]\n",
    "        for x in range(len(line)):\n",
    "            line[x].set_coordinate(x,y)\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        new_lines.extend(line)\n",
    "\n",
    "\n",
    "    new_lines.sort(key=lambda x:x.left_top_x)\n",
    "    last_left=None\n",
    "    last_right = None\n",
    "    col_lines = []\n",
    "    line = []\n",
    "    for idx in range(len(new_lines)):\n",
    "        bbox = new_lines[idx]\n",
    "        same_line = False\n",
    "        if last_right is None or ((last_right >= bbox.left_top_x>=last_left)):\n",
    "            same_line = True\n",
    "        if not same_line:\n",
    "            line.sort(key=lambda x:x.left_top_y)\n",
    "            col_lines.append(line)\n",
    "            line = [bbox]\n",
    "        else:\n",
    "            line.append(bbox)\n",
    "        last_right = bbox.right_bottom_x\n",
    "        last_left = bbox.left_top_x\n",
    "    col_lines.append(line)\n",
    "    col_num = 0\n",
    "    row_num=0\n",
    "    for line in col_lines:\n",
    "        x_cnt = {}\n",
    "        for item in line:\n",
    "            if item.x not in x_cnt:\n",
    "                x_cnt[item.x] = 1\n",
    "            else:\n",
    "                x_cnt[item.x] += 1\n",
    "\n",
    "        xlist = list(x_cnt.keys())\n",
    "        xlist.sort(key=lambda x:x_cnt[x],reverse=True)\n",
    "        final_x = xlist[0]\n",
    "        print(final_x)\n",
    "        for item in line:\n",
    "\n",
    "            if '1053138643068149760' in item.text:\n",
    "                pass\n",
    "            item.x=final_x\n",
    "            if item.y>row_num:\n",
    "                row_num=item.y\n",
    "            if item.x>col_num:\n",
    "                col_num=item.x\n",
    "    final_lines = [[box_text(0,0,0,0,\"检测失败\") for j in range(col_num+1)] for i in range(row_num+1)]\n",
    "    for line in col_lines:\n",
    "        for item in line:\n",
    "            try:\n",
    "                final_lines[item.y][item.x] = item\n",
    "            except Exception as ex:\n",
    "                raise ValueError(item.x,item.y,ex)\n",
    "    data={}\n",
    "    for line in final_lines:\n",
    "        for idx,item in enumerate(line):\n",
    "            if idx not in data:\n",
    "                data[idx]=[] \n",
    "            data[idx].append(item.text)\n",
    "            print(len(line))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_path,index=False)\n",
    "def save_bboxes_csv(bboxes,pred_texts,target_file):\n",
    "    length = len(bboxes)\n",
    "    x_1 = []\n",
    "    y_1 = []\n",
    "    x_2 = []\n",
    "    y_2 = []\n",
    "    for i in range(length):\n",
    "        box = bboxes[i]\n",
    "        x_1.append(box[0])\n",
    "        y_1.append(box[1])\n",
    "        x_2.append(box[2])\n",
    "        y_2.append(box[3])\n",
    "    df = pd.DataFrame({\n",
    "        \"x_1\":x_1,\n",
    "        \"y_1\":y_1,\n",
    "        \"x_2\":x_2,\n",
    "        \"y_2\":y_2,\n",
    "        \"text\":pred_texts,\n",
    "    })\n",
    "    df.to_csv(target_file,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Volumes/dataset1/data/traderecord/eng/processed\"\n",
    "path=\"/Users/androidjk/projects/surya/results/processed/截屏2024-12-28 00_43_01_7_origin.png\"\n",
    "sys.argv = ['', path, '--results_dir', './results','--image','--debug']\n",
    "parser = argparse.ArgumentParser(description=\"Detect bboxes in an input file or folder (PDFs or image).\")\n",
    "parser.add_argument(\"input_path\", type=str, help=\"Path to pdf or image file or folder to detect bboxes in.\")\n",
    "parser.add_argument(\"--results_dir\", type=str, help=\"Path to JSON file with OCR results.\", default=os.path.join(settings.RESULT_DIR, \"surya\"))\n",
    "parser.add_argument(\"--max\", type=int, help=\"Maximum number of pages to process.\", default=None)\n",
    "parser.add_argument(\"--start_page\", type=int, help=\"Page to start processing at.\", default=0)\n",
    "parser.add_argument(\"--images\", action=\"store_true\", help=\"Save images of detected bboxes.\", default=False)\n",
    "parser.add_argument(\"--langs\", type=str, help=\"Optional language(s) to use for OCR. Comma separate for multiple. Can be a capitalized language name, or a 2-letter ISO 639 code.\", default=None)\n",
    "parser.add_argument(\"--lang_file\", type=str, help=\"Optional path to file with languages to use for OCR. Should be a JSON dict with file names as keys, and the value being a list of language codes/names.\", default=None)\n",
    "parser.add_argument(\"--debug\", action=\"store_true\", help=\"Enable debug logging.\", default=False)\n",
    "args = parser.parse_args()\n",
    "\n",
    "if os.path.isdir(args.input_path):\n",
    "    images, names, _ = load_from_folder(args.input_path, args.max, args.start_page)\n",
    "    highres_images, _, _ = load_from_folder(args.input_path, args.max, args.start_page, settings.IMAGE_DPI_HIGHRES)\n",
    "    folder_name = os.path.basename(args.input_path)\n",
    "else:\n",
    "    images, names, _ = load_from_file(args.input_path, args.max, args.start_page)\n",
    "    highres_images, _, _ = load_from_file(args.input_path, args.max, args.start_page, settings.IMAGE_DPI_HIGHRES)\n",
    "    folder_name = os.path.basename(args.input_path).split(\".\")[0]\n",
    "\n",
    "if args.lang_file:\n",
    "    # We got all of our language settings from a file\n",
    "    langs = load_lang_file(args.lang_file, names)\n",
    "    for lang in langs:\n",
    "        replace_lang_with_code(lang)\n",
    "    image_langs = langs\n",
    "elif args.langs:\n",
    "    # We got our language settings from the input\n",
    "    langs = args.langs.split(\",\")\n",
    "    replace_lang_with_code(langs)\n",
    "    image_langs = [langs] * len(images)\n",
    "else:\n",
    "    image_langs = [None] * len(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model vikp/surya_det3 on device mps with dtype torch.float16\n",
      "Loaded recognition model vikp/surya_rec2 on device mps with dtype torch.float16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "det_processor = load_detection_processor()\n",
    "det_model = load_detection_model()\n",
    "\n",
    "rec_model = load_recognition_model()\n",
    "rec_processor = load_recognition_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded detection model vikp/surya_det3 on device mps with dtype torch.float16\n",
      "Loaded recognition model vikp/surya_rec2 on device mps with dtype torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "Recognizing Text: 100%|██████████| 12/12 [11:42<00:00, 58.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR took 703.70 seconds\n",
      "Max chars: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "det_processor = load_detection_processor()\n",
    "det_model = load_detection_model()\n",
    "\n",
    "rec_model = load_recognition_model()\n",
    "rec_processor = load_recognition_processor()\n",
    "\n",
    "\n",
    "result_path = os.path.join(args.results_dir, folder_name)\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "start = time.time()\n",
    "torch.cuda.empty_cache()\n",
    "predictions_by_image = run_ocr(images, image_langs, det_model, det_processor, rec_model, rec_processor, highres_images=highres_images)\n",
    "if args.debug:\n",
    "    print(f\"OCR took {time.time() - start:.2f} seconds\")\n",
    "    max_chars = max([len(l.text) for p in predictions_by_image for l in p.text_lines])\n",
    "    print(f\"Max chars: {max_chars}\")\n",
    "\n",
    "\n",
    "for idx, (name, image, pred, langs) in enumerate(zip(names, images, predictions_by_image, image_langs)):\n",
    "    \n",
    "    bboxes = [l.bbox for l in pred.text_lines]\n",
    "    pred_text = [l.text for l in pred.text_lines]\n",
    "    # page_image = draw_text_on_image(bboxes, pred_text, image.size, langs, has_math=\"_math\" in langs if langs else False)\n",
    "    # page_image.save(os.path.join(result_path, f\"{name}_{idx}.png\"))\n",
    "    # image.save(os.path.join(result_path, f\"{name}_{idx}_origin.png\"))\n",
    "    # generate_csv(bboxes,pred_text,os.path.join(result_path, f\"{name}_{idx}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bboxes_csv(bboxes,pred_text,\"/Users/androidjk/projects/surya/results/processed/截屏2024-12-28 00_43_01_7_origin_box.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, (name, image, pred, langs) in enumerate(zip(names, images, predictions_by_image, image_langs)):\n",
    "    bboxes = [l.bbox for l in pred.text_lines]\n",
    "    pred_text = [l.text for l in pred.text_lines]\n",
    "    print(idx,pred_text,end='\\n')\n",
    "    print(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate_csv(bboxes,pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,line in enumerate(lines):\n",
    "    print(idx,len(line),[(idx,item.text) for idx,item in enumerate(line)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
