{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_35_25\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_34_45\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_35_57\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_36_26\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_35_10\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_34_14\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_46_59\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_48_05\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_35_44\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_33_05\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_33_30\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_34_57\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_34_33\n",
      "/Volumes/dataset1/data/traderecord/eng/processed/截屏2025-01-05 17_34_01\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "os.environ['HF_ENDPOINT']='https://hf-mirror.com'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF']='expandable_segments:True'\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO']='0.0'\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from surya.input.langs import replace_lang_with_code\n",
    "from surya.input.load import load_from_folder, load_from_file, load_lang_file\n",
    "from surya.model.detection.model import load_model as load_detection_model, load_processor as load_detection_processor\n",
    "from surya.model.recognition.model import load_model as load_recognition_model\n",
    "from surya.model.recognition.processor import load_processor as load_recognition_processor\n",
    "from surya.ocr import run_ocr\n",
    "from surya.postprocessing.text import draw_text_on_image\n",
    "from surya.settings import settings\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def process_image_bw(image):\n",
    "    def convert_color(image,hit_colors,target_color,reverse=False):\n",
    "\n",
    "        image_array = np.array(image)\n",
    "        for color in hit_colors:\n",
    "            expre = ((image_array[:, :, 0] == color[0]) & (image_array[:, :, 1] == color[1]) & (image_array[:, :, 2] == color[2]))\n",
    "            if reverse:\n",
    "                expre = ~expre\n",
    "            image_array[expre] = target_color\n",
    "        processed_image = Image.fromarray(image_array)\n",
    "        return processed_image\n",
    "    base_green = [0,40,32]\n",
    "    base_red = [47,18,0]\n",
    "    gap =5\n",
    "    colors = []\n",
    "    for i in range(gap):\n",
    "        for j in range(gap):\n",
    "            this_color = [base_green[0],base_green[1]+i,base_green[2]+j]\n",
    "            minus_color = [base_green[0],base_green[1]-i,base_green[2]-j]\n",
    "            colors.append(this_color)\n",
    "            colors.append(minus_color)\n",
    "            this_color = [base_red[0]+j,base_red[1]+i,base_red[2]]\n",
    "            minus_color = [base_red[0]-j,base_red[1]-i,base_red[2]]\n",
    "            colors.append(this_color)\n",
    "            colors.append(minus_color)\n",
    "    colors.extend([[0,0,0],[49,19,0],[0,68,54],[46,18,0],[68,27,12],[82,39,23],[0,68,54],[15,78,67]])\n",
    "\n",
    "    new_image=convert_color(image,colors,target_color=[0,0,0])\n",
    "    new_image=convert_color(new_image,[[0,0,0]],target_color=[255,255,255],reverse=True)\n",
    "    image_array = np.array(new_image)\n",
    "    white_expre = ((image_array[:, :, 0] == 255) & (image_array[:, :, 1] == 255) & (image_array[:, :, 2] == 255))\n",
    "    black_expre = ((image_array[:, :, 0] == 0) & (image_array[:, :, 1] == 0) & (image_array[:, :, 2] == 0))\n",
    "    image_array[white_expre] = [0,0,0]\n",
    "    image_array[black_expre] = [255,255,255]\n",
    "    new_image = Image.fromarray(image_array)\n",
    "    return new_image\n",
    "input_path = \"/Volumes/dataset1/data/traderecord/eng\"\n",
    "max  = None\n",
    "start_page = 0\n",
    "images, names, _ = load_from_folder(input_path, max, start_page)\n",
    "\n",
    "processed_path = os.path.join(input_path,\"processed\")\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "for idx,image in enumerate(images):\n",
    "    new_image = process_image_bw(image)\n",
    "    file_save_path = os.path.join(processed_path,names[idx])\n",
    "    print(file_save_path)\n",
    "    new_image.save(file_save_path+\".png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
